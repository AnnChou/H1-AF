{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9fd1e099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import joblib\n",
    "import cv2\n",
    "\n",
    "import gradio as gr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23f2e387",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_path_to = 'G:/.shortcut-targets-by-id/10wVB-YsfTmmpZyUo8jBH1cDOkVWVx5N1/T1 Project/Data/'\n",
    "os.path.exists(g_path_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7fd0fdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to = 'Data/Training-Splitted'\n",
    "os.path.exists(path_to)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "527a251b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_img2_path_to = 'Data/predicted_images2'\n",
    "os.path.exists(pred_img2_path_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c347adc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(path_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc5833ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path_to = 'Modelfile/'\n",
    "os.path.exists(model_path_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc587cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model_joblib_name = 'pixelCt_pixelSz_toHeadCir_rfReg.joblib'\n",
    "rf_model_joblib_file = model_path_to+rf_model_joblib_name  \n",
    "os.path.exists(rf_model_joblib_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec40836a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Modelfile/pixelCt_pixelSz_toHeadCir_rfReg.joblib'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model_joblib_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2d7adee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import joblib\n",
    "\n",
    "# Load the trained Random Forest model\n",
    "rf_model = joblib.load(rf_model_joblib_file)\n",
    "\n",
    "# to use rf_model.predict(input_data)   #input_data has column of feature_names = ['pixel_count','pixel size(mm)']\n",
    "feature_names = ['pixel_count','pixel size(mm)']\n",
    "\n",
    "# X = input_dffeature_names]\n",
    "# y_pred  = rf_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fb931e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88e5cb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### function get_pixe_count get_pixel_count(img_data_path, filename) ###  duplicate code from above.\n",
    "def get_pixel_count(img_data_path, filename):\n",
    "    file_path = os.path.join(img_data_path, filename)\n",
    "    if os.path.exists(file_path):\n",
    "        label = Image.open(file_path)\n",
    "        label = np.array(label)\n",
    "        label = tf.convert_to_tensor(label)\n",
    "        label = tf.cast(label, tf.float32) / 255.0\n",
    "        label = tf.cast(label, tf.int32)\n",
    "        pixel_count = np.sum(label)\n",
    "    else:\n",
    "        print(\"No such file: \" + filename)\n",
    "        pixel_count = np.nan\n",
    "\n",
    "    return pixel_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "273eec06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annch\\.conda\\envs\\unet-py39\\lib\\site-packages\\gradio\\inputs.py:257: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n",
      "C:\\Users\\annch\\.conda\\envs\\unet-py39\\lib\\site-packages\\gradio\\deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### get_pixel_count_gradio demo ###\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "\n",
    "def get_pixel_count_gradio(input_img):\n",
    "    label = np.array(input_img)\n",
    "    label = tf.convert_to_tensor(label)\n",
    "    label = tf.cast(label, tf.float32) / 255.0\n",
    "    label = tf.cast(label, tf.int32)\n",
    "    pixel_count = np.sum(label)\n",
    "    print(pixel_count)\n",
    "    return pixel_count\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=get_pixel_count_gradio,\n",
    "    inputs=gr.inputs.Image(shape=(800, 540)),\n",
    "    outputs=\"number\"\n",
    ")\n",
    "\n",
    "#demo.launch(share=True)\n",
    "demo.launch()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b4a15a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annch\\.conda\\envs\\unet-py39\\lib\\site-packages\\gradio\\inputs.py:257: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n",
      "C:\\Users\\annch\\.conda\\envs\\unet-py39\\lib\\site-packages\\gradio\\deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7865\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annch\\.conda\\envs\\unet-py39\\lib\\site-packages\\gradio\\inputs.py:257: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n",
      "C:\\Users\\annch\\.conda\\envs\\unet-py39\\lib\\site-packages\\gradio\\deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n",
      "C:\\Users\\annch\\.conda\\envs\\unet-py39\\lib\\site-packages\\gradio\\inputs.py:59: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n",
      "C:\\Users\\annch\\.conda\\envs\\unet-py39\\lib\\site-packages\\gradio\\outputs.py:22: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7866\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000620\n",
      "335.5752000000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annch\\.conda\\envs\\unet-py39\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010420\n",
      "335.5752000000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annch\\.conda\\envs\\unet-py39\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gradio as gr\n",
    "import joblib\n",
    "\n",
    "# Load the RF model\n",
    "#rf_model = joblib.load(\"rf_model_joblib_file\")\n",
    "\n",
    "### get_pixel_count_gradio demo ###\n",
    "def get_pixel_count_gradio(input_img):\n",
    "    label = np.array(input_img)\n",
    "    pixel_count = np.sum(label)\n",
    "    print(pixel_count)\n",
    "    return pixel_count\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=get_pixel_count_gradio,\n",
    "    inputs=gr.inputs.Image(shape=(800, 540)),\n",
    "    outputs=\"number\"\n",
    ")\n",
    "\n",
    "demo.launch()\n",
    "\n",
    "def predict_head_circumference(input_img, pixel_size):\n",
    "    # Use the pixel size and other features to make a prediction\n",
    "    feature_names = ['pixel_count', 'pixel size(mm)']  # Add other relevant features here\n",
    "    pixel_count = get_pixel_count_gradio(input_img)\n",
    "    \n",
    "    prediction = rf_model.predict([[pixel_count, pixel_size]])[0]\n",
    "    print(prediction)\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "inputs = [\n",
    "    gr.inputs.Image(label=\"Image\"),\n",
    "    gr.inputs.Number(label=\"Pixel Size (mm)\")\n",
    "]\n",
    "\n",
    "output = gr.outputs.Textbox(label=\"Head Circumference (mm)\")\n",
    "\n",
    "gr_interface = gr.Interface(\n",
    "    fn=predict_head_circumference,\n",
    "    inputs=inputs,\n",
    "    outputs=output,\n",
    "    title=\"Head Circumference Predictor\",\n",
    "    description=\"Predicts the head circumference based on an image and pixel size.\",\n",
    ")\n",
    "\n",
    "gr_interface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8dbfb01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annch\\.conda\\envs\\unet-py39\\lib\\site-packages\\gradio\\inputs.py:257: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n",
      "C:\\Users\\annch\\.conda\\envs\\unet-py39\\lib\\site-packages\\gradio\\deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n",
      "C:\\Users\\annch\\.conda\\envs\\unet-py39\\lib\\site-packages\\gradio\\inputs.py:59: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n",
      "C:\\Users\\annch\\.conda\\envs\\unet-py39\\lib\\site-packages\\gradio\\outputs.py:22: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7864\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annch\\.conda\\envs\\unet-py39\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\annch\\.conda\\envs\\unet-py39\\lib\\site-packages\\gradio\\routes.py\", line 394, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"C:\\Users\\annch\\.conda\\envs\\unet-py39\\lib\\site-packages\\gradio\\blocks.py\", line 1075, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"C:\\Users\\annch\\.conda\\envs\\unet-py39\\lib\\site-packages\\gradio\\blocks.py\", line 884, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"C:\\Users\\annch\\.conda\\envs\\unet-py39\\lib\\site-packages\\anyio\\to_thread.py\", line 28, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(func, *args, cancellable=cancellable,\n",
      "  File \"C:\\Users\\annch\\.conda\\envs\\unet-py39\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 818, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"C:\\Users\\annch\\.conda\\envs\\unet-py39\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 754, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"C:\\Users\\annch\\AppData\\Local\\Temp\\ipykernel_7344\\3505780817.py\", line 22, in predict_head_circumference\n",
      "    prediction = rf_model.predict([pixel_count,pixel_size])[0]\n",
      "  File \"C:\\Users\\annch\\.conda\\envs\\unet-py39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 981, in predict\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\Users\\annch\\.conda\\envs\\unet-py39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 602, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\Users\\annch\\.conda\\envs\\unet-py39\\lib\\site-packages\\sklearn\\base.py\", line 565, in _validate_data\n",
      "    X = check_array(X, input_name=\"X\", **check_params)\n",
      "  File \"C:\\Users\\annch\\.conda\\envs\\unet-py39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 902, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Expected 2D array, got 1D array instead:\n",
      "array=[5436.  300.].\n",
      "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#import gradio as gr\n",
    "#import pandas as pd\n",
    "#import joblib\n",
    "#import cv2\n",
    "\n",
    "# Load the RF model\n",
    "rf_model = joblib.load(rf_model_joblib_file)\n",
    "\n",
    "# Load the CSV file with pixel size data\n",
    "#csv_file_path = 'pixel_size_data.csv'\n",
    "#pixel_size_data = pd.read_csv(csv_file_path)\n",
    "\n",
    "def predict_head_circumference(input_img, pixel_size):\n",
    "    # Process the image (e.g., resize, normalize, etc.)\n",
    "    #processed_image = preprocess_image(image)  #image already in binary form\n",
    "    \n",
    "    # Use the pixel size and other features to make a prediction\n",
    "    feature_names = ['pixel_count','pixel size(mm)']  # Add other relevant features here\n",
    "    pixel_count = get_pixel_count_gradio(input_img)\n",
    "    pixel_size = pixel_size\n",
    "    \n",
    "    prediction = rf_model.predict([pixel_count,pixel_size])[0]\n",
    "    print(prediction)\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "#def preprocess_image(image):\n",
    "#    # Preprocess the image (e.g., resize, normalize, etc.)\n",
    "#    # Modify this function based on your specific image preprocessing requirements\n",
    "#    processed_image = cv2.resize(image, (224, 224))\n",
    "#    processed_image = processed_image / 255.0  # Normalize pixel values\n",
    "    \n",
    "#    return processed_image\n",
    "\n",
    "# Define the input and output interfaces for Gradio\n",
    "inputs = [\n",
    "    gr.inputs.Image(label=\"Image\"),\n",
    "    gr.inputs.Number(label=\"Pixel Size (mm)\")\n",
    "]\n",
    "\n",
    "output = gr.outputs.Textbox(label=\"Head Circumference (mm)\")\n",
    "\n",
    "# Create the Gradio interface\n",
    "gr_interface = gr.Interface(\n",
    "    fn=predict_head_circumference,\n",
    "    inputs=inputs,\n",
    "    outputs=output,\n",
    "    title=\"Head Circumference Predictor\",\n",
    "    description=\"Predicts the head circumference based on an image and pixel size.\",\n",
    ")\n",
    "\n",
    "# Run the Gradio app\n",
    "gr_interface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "06db1ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annch\\.conda\\envs\\unet-py39\\lib\\site-packages\\gradio\\outputs.py:22: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7871\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7871/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def greet(name):\n",
    "    return \"Hello \" + name + \"!\"\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=greet,\n",
    "    inputs=gr.Textbox(lines=2, placeholder=\"Name Here...\"),\n",
    "    #outputs=\"text\",\n",
    "    outputs=gr.outputs.Textbox(label=\"Prediction\")\n",
    ")\n",
    "demo.launch()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667961cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fded7624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gradio as gr\n",
    "\n",
    "def sepia(input_img):\n",
    "    sepia_filter = np.array([\n",
    "        [0.393, 0.769, 0.189], \n",
    "        [0.349, 0.686, 0.168], \n",
    "        [0.272, 0.534, 0.131]\n",
    "    ])\n",
    "    sepia_img = input_img.dot(sepia_filter.T)\n",
    "    sepia_img /= sepia_img.max()\n",
    "    return sepia_img\n",
    "\n",
    "demo = gr.Interface(sepia, gr.Image(shape=(200, 200)), \"image\")\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49f23fa2",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'Data/Training-Splitted/train\\\\Annotation'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load the first image in the folder\u001b[39;00m\n\u001b[0;32m      2\u001b[0m first_image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(image_folder, image_files[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m----> 3\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfirst_image_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\unet-py39\\lib\\site-packages\\PIL\\Image.py:3227\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3224\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[0;32m   3226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[1;32m-> 3227\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3228\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3230\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'Data/Training-Splitted/train\\\\Annotation'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a9e86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Get the input shape\n",
    "input_shape = image.size\n",
    "\n",
    "print(\"Input shape:\", input_shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
